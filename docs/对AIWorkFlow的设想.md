---
date: 2025-06-29
---

## AI 工作流设计构想

### 引言

当我使用像 Manus 或 SWE-Agent 这类智能体系统（Agentic System）来处理复杂的开发任务时，常常会遇到很高的失败率。如果我们给智能体一个诸如“构建一个全栈应用”这样笼统的目标，整个过程很容易因为目标模糊、中间步骤设计有误或无法从错误中恢复而偏离轨道。这迫使我们不得不从头再来，造成大量时间和计算资源（tokens）的浪费。

另一个问题是，大多数智能体工具的运行方式如同一个“黑箱”。我们发布一个指令后，只能被动地观察它的“意识流”或行为输出，缺乏在关键决策点进行干预、批准或在其误解需求时进行纠正的机制。这导致了最终结果的不可靠，也让我们难以真正信任这些系统。

为了让 AI 智能体能够可靠地执行复杂、多步骤的工程任务，并赋予人类对过程的有效控制权，我们设计了这套工作流设计指南。这套原则与规则集能帮助我们将任何复杂的任务，构建成一个透明、可调试且高度可靠的计划。

我们的目标是，将 AI 软件开发从一门不可预测的艺术，转变为一门系统化的工程学科，在智能体的自主性与人类的监督之间取得完美平衡。

### 设计原则

我们创建这套工作流设计指南，是基于我们对软件工程与 AI 智能体协作的“第一性原理”思考，我们坚信以下三个基本趋势：

1. **AI 的能力会持续进步，但复杂任务永远需要结构化的监督。** 虽然大语言模型（LLM）的编码能力会越来越强，但真正的工程实践涉及到架构设计、权衡取舍和分步执行。一个结构化的计划能将人机交互从简单的“发号施令”提升到“项目管理”的层面。
2. **对 AI 驱动的复杂任务的需求，将永远超过 AI 的自主能力。** 随着我们的期望从“写一个函数”增长到“构建并管理一个分布式系统”，对稳健规划、错误处理和人类干预的需求只会变得更加关键，而非减弱。
3. **当 AI 智能体负责主要开发工作时，人类的关注点将从逐行代码的可读性，转向整个系统的可靠性与可控性。** 人类没有时间或意愿去审查 AI 生成的每一行代码。相反，我们更关心架构是否合理、测试是否通过以及关键决策点是否得到批准。为了最大化智能体的效率，我们必须构建透明且可控的工作流。
4. **AI 生成系统的可靠性，必须由完备的测试和“人在回路中”（Human-in-the-Loop）的治理来保障，而非寄希望于侥幸。** 结构化的工作流允许我们设立专门的测试阶段和明确的审批关卡，确保最终产品符合人类的标准。
5. **如果人类工程师需要理解流程中的某个特定部分，结构化的计划能为每一步的意图和产物提供清晰的上下文。** 我们无需担心智能体的执行过程难以理解——一个设计良好的工作流，应该让智能体成为一个真正的协作者，其行为是透明且可审计的。

### 基本工作流设计规则

基于上述核心原则，我们精心设计了一套 AI 智能体工作流应遵循的基本规则：

1. **分解意图（Decompose into Intents）：** 将一个宏大、模糊的目标分解为一系列更小、职责单一的步骤。每一步都应由一个清晰、高层次的“意图”来定义，而非一个底层的命令。
2. **分配具体工具（Assign Concrete Tools）：** 为每个意图明确指定执行它的智能体。这个智能体应该是工具箱中一个具体、可用的工具（例如：Python、Shell、文件操作、谷歌搜索等）。
3. **定义清晰依赖（Define Clear Dependencies）：** 使用 `dependencies` 关键字将任务组织成一个**有向无环图（DAG）**，以确保执行顺序的逻辑性和可预测性。
4. **明确交付物（Specify Deliverables with Artifacts）：** 为每个任务明确声明其预期的**交付物（artifacts）**，即产出文件或结果。这在任务之间创建了清晰的“契约”，使数据流变得透明。
5. **实现具体的人机交互节点（Implement Concrete Human-in-the-Loop Gates）：** 不要依赖抽象的“人工审核”概念，而应实现基于工具的、具体的交互机制。例如，生成一个评审文件，并用一个 Shell 脚本轮询检查用户是否已创建包含决策的响应文件。
6. **规划并行探索（Plan for Parallelism）：** 对于那些具有创造性或存在多种解决方案的复杂步骤，使用 `variants` 指令来引导智能体并行探索多种实现方法。
7. **隔离功能与促进复用（Isolate Functionality and Promote Reuse）：** 将通用的逻辑或模块抽象成独立的任务序列，使其可以被其他工作流触发调用，从而减少冗余。
8. **让智能体处理实现细节（Let the Agent Handle Implementation Details）：** 计划只定义“做什么”（意图），而不定义“怎么做”。**智能体编排器（Agent Orchestrator）** 负责解释意图，并为指定的工具生成必要的代码或命令。

### 示例：自动化 Lisp 编译器构建

#### 原始方法：模糊、笼统的指令

传统上，我们会用一个单一、笼统的指令来驱动 AI 智能体：

> “请用 Python 构建一个简单的 Lisp 编译器。它需要能解析 S-表达式，处理基本算术运算，并带有一个命令行界面。请确保其结构良好。”

这种方法极易失败。智能体可能会选择一个次优的解析策略，生成的代码集成度不高，或者在某个细节上卡住而我们却无法干预。整个过程就是一个“黑箱”。

#### 结构化工作流：可执行的意图导向型 YAML (I-YAML)

相反，我们可以使用我们设计的意图导向型 YAML 格式来构建这个复杂任务。这个计划不是代码，而是一个为执行提供清晰度、可控性和可靠性的蓝图。

```yaml
# 任务计划：构建 Lisp 编译器（基于可用工具的可执行版本）
name: "构建 Lisp 编译器的可执行计划"
description: "一个将高级意图映射到具体工具（Python、Shell、文件）以构建 Lisp 编译器的高级计划。"
version: "3.0"

tasks:
  - id: setup_project_structure
    name: "1. 创建项目目录结构"
    agent: Shell # 明确使用 Shell 工具
    intent: "为项目创建必要的基础目录：'src' 用于存放源代码，'tests' 用于存放测试文件。"
    artifacts: ["./src", "./tests"]

  - id: implement_lexer
    name: "2. 实现词法分析器（Lexer）"
    agent: Python # 意图是生成 Python 代码，因此使用 Python 工具
    intent: "编写一个 Python 脚本，创建并写入 'src/lexer.py' 文件。该文件必须包含一个 `tokenize` 函数，能够将 Lisp 源代码字符串分解为 token 列表。"
    artifacts: ["src/lexer.py"]

  - id: implement_parser
    name: "3. 实现语法分析器（Parser）"
    agent: Python
    intent: "编写一个 Python 脚本，创建并写入 'src/parser.py' 文件。该文件必须包含一个 `parse` 函数，能够将 token 列表转换为抽象语法树（AST）。"
    artifacts: ["src/parser.py"]

  - id: propose_transpiler_code
    name: "4. 生成两种代码转译器方案"
    agent: Python
    variants: 2 # Python 智能体将被指示执行两次，每次生成不同的实现
    intent: "为 Lisp AST 到 Python 代码的转译器生成两种不同的实现方案，并分别保存到 'build/transpiler_v1.py' 和 'build/transpiler_v2.py'。"
    artifacts: ["build/transpiler_v1.py", "build/transpiler_v2.py"]

  - id: prepare_human_review
    name: "5. 准备人工审核材料"
    agent: Python # 使用 Python 工具准备一个供人类阅读的文件
    intent: "读取两种转译器方案的内容，进行格式化，并写入名为 'REVIEW_REQUEST.md' 的文件。该文件必须清晰地指示用户创建一个名为 'selection.txt' 的文件，并写入 '1' 或 '2' 来做出选择。"
    artifacts: ["REVIEW_REQUEST.md"]

  - id: wait_for_human_selection
    name: "6. [审核] 等待人工选择"
    agent: HumanReview # 人类可以选择代码版本，或直接在文件中修改代码。

  - id: improve_selected_transpiler
    name: "7. 改进选定的转译器"
    agent: Python
    intent: "将选定的转译器代码改进后，写入最终的 'src/transpiler.py' 文件。"
    artifacts: ["src/transpiler.py"]

  - id: implement_cli_and_tests
    name: "8. 实现命令行界面并运行测试"
    agent: Python
    dependencies: [improve_selected_transpiler] # 依赖于改进后的转译器
    intent: "创建一个主入口脚本 `lisp_compiler.py` 和一个测试脚本 `tests/run_tests.py`。使用 `unittest` 框架进行单元测试和集成测试，并打印测试报告。"
    artifacts: ["test_report.txt"]
```

#### “解压”计划：智能体的解释过程

这个结构化的 YAML 不仅是一个计划，更是一个可执行的规范。**智能体编排器（Agent Orchestrator）** 会逐一解释并执行这个计划。对人类而言，它提供了清晰的全局视图；对智能体而言，它提供了明确无误的指令。

让我们看看编排器如何处理一个任务：

**解析 `id: implement_lexer` 任务**

1. **读取任务**：编排器识别到 `implement_lexer` 任务。
2. **检查依赖**：它确认前置任务 `setup_project_structure` 已完成。
3. **识别智能体与意图**：它看到 `agent: Python` 和 `intent: "编写一个 Python 脚本，创建并写入 'src/lexer.py'..."`。
4. **生成并执行代码**：编排器本身由大语言模型驱动，它会调用用户指定的工具来完成这个意图。
5. **验证交付物**：编排器确认交付物 `src/lexer.py` 已成功创建，并将任务标记为完成。

这个过程将一个高层次的目标，转化为一个可验证的、基于工具的行动，充分展示了从模糊指令转向精确、意图驱动的计划所带来的强大优势。“人在回路中”的步骤也以同样的精度进行处理，使人类的控制成为自动化工作流中一个可靠的组成部分。

### 结论

本次探索展示了将系统化的工作流设计应用于 AI 驱动的软件工程所蕴含的巨大潜力。通过摒弃单一、庞杂的指令，转向结构化、意图导向的计划，我们将智能体系统从不可预测的“神秘黑箱”转变为可靠的工程伙伴。遵循这套精心设计的指南——强调目标分解、工具化执行、明确契约和具体的人机交互机制——我们能够显著提升 AI 智能体的可靠性与可控性。这种方法降低了失败率，增强了透明度，并最终在任何复杂度的软件项目上，实现了真正的人机协作。